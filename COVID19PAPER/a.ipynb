{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.linalg as slin\n",
    "import scipy.optimize as sopt\n",
    "from scipy.special import expit as sigmoid\n",
    "import csv\n",
    "import sys\n",
    "import igraph as ig\n",
    "import os\n",
    "import timeit\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def notears_linear(X,Z,lambda1,lambda2,loss_type, max_iter=100, h_tol=1e-8, rho_max=1e+16, w_threshold=0.3):\n",
    "\n",
    "    ## divided W into covariates and network\n",
    "    full_data=np.concatenate([X,Z],axis=1)\n",
    "    def _divideParameters(W):\n",
    "        W_net=W[0:d]\n",
    "        W_cov=W[d:]\n",
    "        return W_net,W_cov\n",
    "\n",
    "    ## Nothing needs to be changed here\n",
    "    def _loss(W):\n",
    "        \n",
    "        M = np.matmul(full_data,W)\n",
    "        if loss_type == 'l2':\n",
    "            R = X - M\n",
    "            loss = 0.5 / full_data.shape[0] * (R ** 2).sum()\n",
    "            G_loss = - 1.0 / full_data.shape[0] * np.matmul(full_data.T,R)\n",
    "        else:\n",
    "            raise ValueError('unknown loss type')\n",
    "        return loss, G_loss\n",
    "\n",
    "    ## Nothing needs to be changed here\n",
    "    def _h(W):\n",
    "        \n",
    "        W_net,W_cov=_divideParameters(W)\n",
    "        E = slin.expm(W_net * W_net)  # (Zheng et al. 2018)\n",
    "        h = np.trace(E) - d\n",
    "        #     # A different formulation, slightly faster at the cost of numerical stability\n",
    "        #     M = np.eye(d) + W * W / d  # (Yu et al. 2019)\n",
    "        #     E = np.linalg.matrix_power(M, d - 1)\n",
    "        #     h = (E.T * M).sum() - d\n",
    "        G_h = E.T * W_net * 2\n",
    "        G_h_expand=np.concatenate([G_h,np.zeros([m,d])],axis=0)\n",
    "        return h, G_h_expand\n",
    "\n",
    "    ## Nothing needs to be changed here except for the dimension\n",
    "    def _adj(w):\n",
    "        \n",
    "        return (w[:((d+m) * d)] - w[((d+m) * d):]).reshape([(d+m), d])\n",
    "\n",
    "    def _func(w):\n",
    "        \n",
    "        W = _adj(w)\n",
    "        W_net,W_cov=_divideParameters(W)\n",
    "        loss, G_loss = _loss(W)\n",
    "        h, G_h = _h(W)\n",
    "        obj = loss + 0.5 * rho * h * h + alpha * h + lambda1 * W_net.sum()+lambda2* W_cov.sum()\n",
    "        G_smooth = G_loss + (rho * h + alpha) * G_h\n",
    "        G_nonsmooth=np.concatenate([lambda1*np.ones([d,d]),lambda2*np.ones([m,d])])\n",
    "        g_obj = np.concatenate((G_smooth + G_nonsmooth, - G_smooth + G_nonsmooth), axis=None)\n",
    "        return obj, g_obj\n",
    "\n",
    "    n, d = X.shape\n",
    "    ## Added: m=number of covariates\n",
    "    m=Z.shape[1]\n",
    "    w_est, rho, alpha, h = np.zeros(2 * (d+m) * d), 1.0, 0.0, np.inf  # double w_est into (w_pos, w_neg)\n",
    "    bnds = [(0, 0) if i == j else (0, None) for _ in range(2) for i in range(d+m) for j in range(d)]\n",
    "    if loss_type == 'l2':\n",
    "        full_data = full_data - np.mean(full_data, axis=0, keepdims=True)\n",
    "    mycount=0\n",
    "    for _ in range(max_iter):\n",
    "        mycount=mycount+1\n",
    "        print(mycount)\n",
    "        w_new, h_new = None, None\n",
    "        while rho < rho_max:\n",
    "            sol = sopt.minimize(_func, w_est, method='L-BFGS-B', jac=True, bounds=bnds)\n",
    "            w_new = sol.x\n",
    "            h_new, _ = _h(_adj(w_new))\n",
    "            if h_new > 0.25 * h:\n",
    "                rho *= 10\n",
    "            else:\n",
    "                break\n",
    "        w_est, h = w_new, h_new\n",
    "        alpha += rho * h\n",
    "        if h <= h_tol or rho >= rho_max:\n",
    "            break\n",
    "    W_est = _adj(w_est)\n",
    "    #W_est[np.abs(W_est) < w_threshold] = 0\n",
    "    return W_est\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The graph is not a DAG\n"
     ]
    }
   ],
   "source": [
    "# A class to represent a graph object\n",
    "class Graph:\n",
    "    # Constructor\n",
    "    def __init__(self, edges, n):\n",
    " \n",
    "        # A list of lists to represent an adjacency list\n",
    "        self.adjList = [[] for _ in range(n)]\n",
    " \n",
    "        # add edges to the directed graph\n",
    "        for (src, dest) in edges:\n",
    "            self.adjList[src].append(dest)\n",
    " \n",
    " \n",
    "# Perform DFS on the graph and set the departure time of all vertices of the graph\n",
    "def DFS(graph, v, discovered, departure, time):\n",
    " \n",
    "    # mark the current node as discovered\n",
    "    discovered[v] = True\n",
    " \n",
    "    # do for every edge (v, u)\n",
    "    for u in graph.adjList[v]:\n",
    "        # if `u` is not yet discovered\n",
    "        if not discovered[u]:\n",
    "            time = DFS(graph, u, discovered, departure, time)\n",
    " \n",
    "    # ready to backtrack\n",
    "    # set departure time of vertex `v`\n",
    "    departure[v] = time\n",
    "    time = time + 1\n",
    " \n",
    "    return time\n",
    " \n",
    " \n",
    "# Returns true if the given directed graph is DAG\n",
    "def isDAG(graph, n):\n",
    " \n",
    "    # keep track of whether a vertex is discovered or not\n",
    "    discovered = [False] * n\n",
    " \n",
    "    # keep track of the departure time of a vertex in DFS\n",
    "    departure = [None] * n\n",
    " \n",
    "    time = 0\n",
    " \n",
    "    # Perform DFS traversal from all undiscovered vertices\n",
    "    # to visit all connected components of a graph\n",
    "    for i in range(n):\n",
    "        if not discovered[i]:\n",
    "            time = DFS(graph, i, discovered, departure, time)\n",
    " \n",
    "    # check if the given directed graph is DAG or not\n",
    "    for u in range(n):\n",
    " \n",
    "        # check if (u, v) forms a back-edge.\n",
    "        for v in graph.adjList[u]:\n",
    " \n",
    "            # If the departure time of vertex `v` is greater than equal\n",
    "            # to the departure time of `u`, they form a back edge.\n",
    " \n",
    "            # Note that `departure[u]` will be equal to `departure[v]`\n",
    "            # only if `u = v`, i.e., vertex contain an edge to itself\n",
    "            if departure[u] <= departure[v]:\n",
    "                return False\n",
    " \n",
    "    # no back edges\n",
    "    return True\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    " \n",
    "    # List of graph edges as per the above diagram\n",
    "    edges = [(0, 1), (0, 3), (1, 2), (1, 3), (3, 2), (3, 4), (3, 0), (5, 6), (6, 3)]\n",
    " \n",
    "    # total number of nodes in the graph (labelled from 0 to 6)\n",
    "    n = 7\n",
    " \n",
    "    # build a graph from the given edges\n",
    "    graph = Graph(edges, n)\n",
    " \n",
    "    # check if the given directed graph is DAG or not\n",
    "    if isDAG(graph, n):\n",
    "        print('The graph is a DAG')\n",
    "    else:\n",
    "        print('The graph is not a DAG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dagThreshold(G,threshold):\n",
    "    n=G.shape[0]\n",
    "    edgelist=[]\n",
    "    for i in range(0,n):\n",
    "        for j in range(0,n):\n",
    "            if abs(G[i,j])>threshold:\n",
    "                edgelist.append([i,j])\n",
    "    graph = Graph(edgelist, n)\n",
    "    return isDAG(graph,n)\n",
    "\n",
    "def findmin(G):\n",
    "    mymin=0.01\n",
    "    while True:\n",
    "        if dagThreshold(G,mymin)==True:\n",
    "            G[np.abs(G)<=mymin]=0\n",
    "            return G,mymin\n",
    "        else:\n",
    "            mymin=mymin+0.01\n",
    "\n",
    "\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b9/w4wr95zj6xd_8wgpnqk78b2m0000gn/T/ipykernel_44187/2266801531.py:6: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  dataset=pd.read_csv(filepath,\",\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "(93, 93)\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "(93, 93)\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "(93, 93)\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "(93, 93)\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "(93, 93)\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b9/w4wr95zj6xd_8wgpnqk78b2m0000gn/T/ipykernel_44187/2266801531.py:6: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  dataset=pd.read_csv(filepath,\",\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "(85, 85)\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "(85, 85)\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "(85, 85)\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "(85, 85)\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "(85, 85)\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(path):\n",
    "    if file.endswith(\".csv\"):\n",
    "        filename=os.path.splitext(file)[0]\n",
    "        filepath=os.path.join(path,file)\n",
    "        dataset=pd.read_csv(filepath,\",\")\n",
    "        ngene=dataset.shape[1]-2\n",
    "        X_data=dataset.iloc[:,range(1,ngene+1)]\n",
    "        Y_data=dataset.iloc[:,range(ngene+1,ngene+2)]\n",
    "        genelist=dataset.columns[1:ngene+1]\n",
    "        X=X_data.to_numpy()\n",
    "        Y=Y_data.to_numpy()\n",
    "        for hyper in [0.1,0.05,0.01,0.005,0.001]:\n",
    "            random.seed(10)\n",
    "            W_est=notears_linear(X,Y,lambda1=hyper,lambda2=hyper,loss_type=\"l2\",h_tol=1e-8,w_threshold=0.3)\n",
    "            W_coef=W_est[range(0,ngene),:]\n",
    "            W_cova=W_est[range(ngene,ngene+1),:]\n",
    "            W_coef_copy=W_coef.copy()\n",
    "            for i in range(0,W_coef_copy.shape[0]):\n",
    "                W_coef_copy[i,i]=0\n",
    "            finalfit=findmin(W_coef_copy)[0]\n",
    "            NOA=sum(np.abs(finalfit.flatten()>0))\n",
    "            output1=pd.DataFrame(finalfit, columns = dataset.columns[range(1,len(dataset.columns)-1)].tolist(),index=dataset.columns[range(1,len(dataset.columns)-1)].tolist())\n",
    "            print(output1.shape)\n",
    "            #top10gene=np.flip(np.argsort(W_cova_reshape))[0:10]+1\n",
    "            output1.to_csv(\"./Result3/\"+filename+\"NOA\"+str(NOA)+\"hyper\"+str(hyper)+\".csv\")\n",
    "            W_cov_df=pd.DataFrame(W_cova,columns=dataset.columns[range(1,len(dataset.columns)-1)].tolist())\n",
    "            W_cov_df.to_csv(\"./Result3/\"+filename+str(hyper)+\"Cov.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalfit=findmin(W_coef_copy)[0]\n",
    "output1=pd.DataFrame(finalfit, columns = dataset.columns[range(1,len(dataset.columns)-1)].tolist(),index=dataset.columns[range(1,len(dataset.columns)-1)].tolist())\n",
    "#W_cov_df.to_csv(\"chlodowncov.csv\")\n",
    "W_cov_df=pd.DataFrame(W_cova,columns=dataset.columns[range(1,len(dataset.columns)-1)].tolist())\n",
    "W_cov_df.to_csv(\"chlodowncova.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#index=list(range(0,84))\n",
    "#A=random.sample(range(84,702),84)\n",
    "#index_combined=index+A\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(702, 97)\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The graph is not a DAG\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum(np.ndarray.flatten(W_est)!=0)\n",
    "W_coef[np.abs(W_coef) < 0.25]=0\n",
    "W_cova[np.abs(W_cova) < 0.15]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_coef_df=pd.DataFrame(W_coef,columns=genelist,index=genelist)\n",
    "W_cov_df=pd.DataFrame(W_cova,columns=genelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_coef_df.to_csv(\"chlodowncoef.csv\")\n",
    "W_cov_df.to_csv(\"chlodowncov.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([1, 2, 4], 3)\n"
     ]
    }
   ],
   "source": [
    "class DAGLongestPath:\n",
    "    \"\"\"Calculate the longest path in a directed acyclic graph (DAG) in terms of node weights\n",
    "    \n",
    "    Use this class to get (one of) the paths with the largest sum of node weights\n",
    "    in a directed acyclic graph (DAG). After constructing the empty object,\n",
    "    use `add_node(label, weight)` and `add_edge(label1, label2)` to build the graph, \n",
    "    and then call `longest_path` to retrieve the path and the sum of the weights.\n",
    "    This latter operation is destructive and will delete the graph.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Construct a new empty graph.\"\"\"\n",
    "        self.nodes = {}  # Dictionary {<label>:<weight>, ...}\n",
    "        self.edges = {}  # Dictionary of sets dict{ <source_label>: set{<target_label>, ...}, ...}\n",
    "        self.rev_edges = {}  # Dictionary of sets\n",
    "        self.unseen_sources = set()  # Labels of all nodes not processed yet that have no incoming edges\n",
    "        self.longest_in_weight = {}  # Dictionary {<label>:<weight>, ...}\n",
    "        self.longest_in_route = {}   # Dictionary {<label>:[<label>, ...], ...}\n",
    "        self.longest_route = None;   # The longest route (in weights) we have seen\n",
    "        self.longest_route_weight = None;  # The larges weight we have seen\n",
    "    \n",
    "    def add_node(self, label, weight):\n",
    "        \"\"\"Add a node to a graph.\n",
    "        \n",
    "        # Arguments\n",
    "            label: a scalar label for the node\n",
    "            weight: a nonnegative number\n",
    "        \"\"\"\n",
    "        if weight < 0: raise ValueError(\"weight cannot be negative\")\n",
    "        self.nodes[label] = weight\n",
    "        self.edges[label] = set()\n",
    "        self.rev_edges[label] = set()\n",
    "        self.unseen_sources.add(label)\n",
    "        \n",
    "    def add_edge(self, source, target):\n",
    "        \"\"\"Add an edge to a graph.\n",
    "        \n",
    "        # Arguments\n",
    "            source: the label of the source node; it should already exist in the graph\n",
    "            target: the label of the target node; it should already exist in the graph\n",
    "        \"\"\"\n",
    "        if source not in self.nodes: raise ValueError(\"source {} not a node\".format(source))\n",
    "        if target not in self.nodes: raise ValueError(\"target {} not a node\".format(target))\n",
    "        self.edges[source].add(target)\n",
    "        self.rev_edges[target].add(source)\n",
    "        self.unseen_sources.discard(target)\n",
    "        \n",
    "    def __del_edges_from(self, source):\n",
    "        \"\"\"Private method to delete all outgoing edges from a node.\"\"\"\n",
    "        targets = self.edges[source]\n",
    "        self.edges[source] = set()\n",
    "        for target in targets:\n",
    "            self.rev_edges[target].discard(source)\n",
    "            if len(self.rev_edges[target]) == 0: # no incoming edges\n",
    "                self.unseen_sources.add(target)\n",
    "                \n",
    "    def __print(self):\n",
    "        \"\"\"Private method to print information about the graph.\"\"\"\n",
    "        print(\"Nodes, Edges\")\n",
    "        for id, w in self.nodes.items():\n",
    "            print(\"  {}{} = {} -> {}\".format(\n",
    "                's' if id in self.unseen_sources else ' ', \n",
    "                id, \n",
    "                w,\n",
    "                \",\".join([str(x) for x in self.edges[id]])\n",
    "            ))\n",
    "        print(\"Rev-Edges\")\n",
    "        for id, source in self.rev_edges.items():\n",
    "            print(\"  {} <- {}\".format(id, \",\".join([str(x) for x in source])))\n",
    "        print(\"Longest in\")\n",
    "        for id, w in self.nodes.items():\n",
    "            print(\"  {} : {} = {}\".format(\n",
    "                id,\n",
    "                str(self.longest_in_weight.get(id, 0)),\n",
    "                \",\".join([str(x) for x in self.longest_in_route.get(id, [])])\n",
    "            ))        \n",
    "        print(\"\")\n",
    "        \n",
    "        \n",
    "    def longest_path(self):\n",
    "        \"\"\"Return the longest path in the graph in terms of the node weights.\n",
    "        \n",
    "        Warning: This operation is destructive and will delete the graph.\n",
    "        \n",
    "        # Returns\n",
    "            An array of the route (array of labels), and the sum of the weights along the route.\n",
    "        \"\"\"\n",
    "        while len(self.unseen_sources) > 0:\n",
    "            sourcenode = self.unseen_sources.pop()\n",
    "            \n",
    "            new_weight = self.longest_in_weight.get(sourcenode, 0) + self.nodes[sourcenode]\n",
    "            new_route = self.longest_in_route.get(sourcenode, []) + [sourcenode]\n",
    "\n",
    "            if len(self.edges[sourcenode]) == 0: # no outgoing edges; isolated node\n",
    "                if self.longest_route is None or self.longest_route_weight < new_weight:\n",
    "                    self.longest_route = new_route\n",
    "                    self.longest_route_weight = new_weight\n",
    "                continue\n",
    "            \n",
    "            # There are outgoing edges            \n",
    "            for target in self.edges[sourcenode]:\n",
    "                \n",
    "                if self.longest_in_weight.get(target, 0) < new_weight:\n",
    "                    self.longest_in_weight[target] = new_weight\n",
    "                    self.longest_in_route[target] = new_route\n",
    "                \n",
    "            self.__del_edges_from(sourcenode)\n",
    "                \n",
    "        return (self.longest_route, self.longest_route_weight)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    dag = DAGLongestPath()\n",
    "    for i in range(6): dag.add_node(i, 1)\n",
    "    dag.add_edge(3, 5)\n",
    "    dag.add_edge(2, 5)\n",
    "    dag.add_edge(2, 4)\n",
    "    dag.add_edge(1, 2)\n",
    "    print(dag.longest_path())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/Users/taoxu/Desktop/COVID19PAPER/Result/ResultProcessed/Coefficient\"\n",
    "for file in os.listdir(path):\n",
    "    if file.endswith(\".csv\"):\n",
    "        A=pd.read_csv(\"/Users/taoxu/Desktop/COVID19PAPER/Result/ResultProcessed/Coefficient/\"+file,index_col=0)\n",
    "        with open(file+'.txt', 'w') as f:\n",
    "            dag=DAGLongestPath()\n",
    "            for i in range(A.shape[0]):\n",
    "                dag.add_node(i,1)\n",
    "            for j in range(A.shape[0]):\n",
    "                for k in range(A.shape[0]):\n",
    "                    if abs(A.iloc[j,k])>0.001:\n",
    "            \n",
    "                        dag.add_edge(j,k)\n",
    "            result=dag.longest_path()\n",
    "            colnames=list(A.columns)\n",
    "            geneindex=result[0]\n",
    "            for l in geneindex:\n",
    "                f.write(colnames[l]+\" \")\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
